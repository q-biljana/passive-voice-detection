{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import re\n",
    "import operator\n",
    "import nltk\n",
    "import json \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotation_re = re.compile(u'[\\u00AB\\u00BB\\u201C\\u201D\\u201E\\u201F\\u2033\\u2036\\u301D\\u301E]')\n",
    "apostrophe_re = re.compile(u'[\\u02BC\\u2019\\u2032]')\n",
    "punct_error_re = re.compile('^([\"\\]\\)\\}]+)(?:[ \\n]|$)')\n",
    "ellipsis_re = re.compile('\\.\\.\\.[\"\\(\\)\\[\\]\\{\\} ] [A-Z]')\n",
    "newline_re = re.compile('\\n[\"\\(\\[\\{ ]*[A-Z]')\n",
    "empty_sent_re = re.compile('^[\\n ]*$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt = \"Skip to main content\"\n",
    "txt=\"The molecular energies were calculated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_draft = nltk.sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(sents_draft[:]):\n",
    "    sents_draft[idx] = sents_draft[idx].replace('e.---g.', 'e.g.').replace('i.---e.', 'i.e.')\n",
    "    if idx > 0:\n",
    "        punct_error = punct_error_re.findall(sent)\n",
    "        if punct_error:\n",
    "            sents_draft[idx-1] += punct_error[0]\n",
    "            sents_draft[idx] = sents_draft[idx][len(punct_error[0])+1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The molecular energies were calculated']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_draft_2 = []\n",
    "for sent in sents_draft:\n",
    "    idx = 0\n",
    "    for ellipsis_case in ellipsis_re.finditer(sent):\n",
    "        sents_draft_2.append(sent[idx:(ellipsis_case.start() + 3)])\n",
    "        idx = ellipsis_case.start() + 3\n",
    "    sents_draft_2.append(sent[idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The molecular energies were calculated']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_draft_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "for sent in sents_draft_2:\n",
    "    idx = 0\n",
    "    for newline_case in newline_re.finditer(sent):\n",
    "        sents.append(sent[idx:(newline_case.start() + 1)])\n",
    "        idx = newline_case.start() + 1\n",
    "    sents.append(sent[idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete empty sentences\n",
    "sents = [sent for sent in sents if not empty_sent_re.match(sent)]\n",
    "\n",
    "# tokenize sentences into words and punctuation marks\n",
    "sents_tokens = [nltk.word_tokenize(sent) for sent in sents]\n",
    "tokens = [token for sent in sents_tokens for token in sent]\n",
    "#data['sentence_numbers'] = [(idx+1) for idx, sent in enumerate(sents_tokens) for token in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The molecular energies were calculated']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'molecular', 'energies', 'were', 'calculated']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'molecular', 'energies', 'were', 'calculated']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'molecular', 'energies', 'were', 'calculated']]\n"
     ]
    }
   ],
   "source": [
    "print (sents_tokens)\n",
    "sents_tokens_tags = nltk.pos_tag(sents_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('molecular', 'JJ'),\n",
       " ('energies', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('calculated', 'VBN')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_tokens_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \t DT\n",
      "molecular \t JJ\n",
      "energies \t NNS\n",
      "were \t VBD\n",
      "calculated \t VBN\n"
     ]
    }
   ],
   "source": [
    "# for sent in sents_tokens_tags:\n",
    "#     print (sent)\n",
    "for token, pos in sents_tokens_tags:\n",
    "    print (token, \"\\t\", pos)\n",
    "#for (token, pos) in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'JJ', 'NNS', 'VBD', 'VBN']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pos for token, pos in sents_tokens_tags ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['pos'] = [pos for token, pos in sents_tokens_tags ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': ['DT', 'JJ', 'NNS', 'VBD', 'VBN']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'molecular', 'energies', 'were', 'calculated']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, token in enumerate(tokens):\n",
    "    if not token[0].isalnum():\n",
    "        if token in [\"'m\", \"'re\", \"'ve\"]:\n",
    "            data['pos'][idx] = 'VBP'\n",
    "        elif token == \"'s\":\n",
    "            if data['pos'][idx] != 'POS':\n",
    "                data['pos'][idx] = 'VBP'\n",
    "        elif token == \"'d\":\n",
    "            data['pos'][idx] = 'VBD'\n",
    "        elif token == \"'ll\":\n",
    "            data['pos'][idx] = 'MD'\n",
    "        elif data['pos'][idx].isalnum():\n",
    "            data['pos'][idx] = 'SYM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'JJ', 'NNS', 'VBD', 'VBN']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix some verbs ending in -ing being counted as nouns\n",
    "for idx, token in enumerate(tokens):\n",
    "    if (token[-3:] == 'ing') and (idx < len(tokens)) and (data['pos'][idx+1] == 'IN'):\n",
    "        data['pos'][idx] = 'VBG'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['verb_groups'] = [None] * len(tokens)\n",
    "verb_group_stack = []\n",
    "verb_group_count = 0\n",
    "for idx, token in enumerate(tokens):\n",
    "    if not verb_group_stack:\n",
    "        if token in [\"be\", \"am\", \"'m\", \"is\", \"'s\", \"are\", \"'re\", \"was\", \"were\", \"will\", \"'ll\", \"wo\", \"have\", \"'ve\", \"has\", \"had\"]:\n",
    "            verb_group_stack.append(idx)\n",
    "    elif token in ['be', 'been', 'being', 'have', 'had']:\n",
    "        verb_group_stack.append(idx)\n",
    "    elif data['pos'][idx][:2] == 'VB':\n",
    "        verb_group_stack.append(idx)\n",
    "        verb_group_count += 1\n",
    "        for i in verb_group_stack:\n",
    "            data['verb_groups'][i] = verb_group_count\n",
    "        verb_group_stack = []\n",
    "    elif data['pos'][idx][:2] not in ['RB', 'PD']:\n",
    "        if len(verb_group_stack) > 1:\n",
    "            verb_group_count += 1\n",
    "            for i in verb_group_stack:\n",
    "                data['verb_groups'][i] = verb_group_count\n",
    "        verb_group_stack = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_group_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'molecular', 'energies', 'were', 'calculated']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, 1, 1]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['verb_groups']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['passive_voice_cases'] = [None] * len(tokens)\n",
    "passive_voice_count = 0\n",
    "for i in range(verb_group_count):\n",
    "    verb_group_stack = [idx for idx in range(len(tokens)) if data['verb_groups'][idx] == i+1]\n",
    "    if data['pos'][verb_group_stack[-1]] in ['VBN', 'VBD']:\n",
    "        for j in verb_group_stack[:-1]:\n",
    "            if tokens[j] in [\"am\", \"'m\", \"is\", \"'s\", \"are\", \"'re\", \"was\", \"were\", \"be\", \"been\", \"being\"]:\n",
    "                passive_voice_count += 1\n",
    "                data['passive_voice_cases'][j] = passive_voice_count\n",
    "                data['passive_voice_cases'][verb_group_stack[-1]] = passive_voice_count\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d277621605e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'passive_voice_cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mNull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Null' is not defined"
     ]
    }
   ],
   "source": [
    "data['passive_voice_cases'].index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
